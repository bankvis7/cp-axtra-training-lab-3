{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2pEJiuLZ-7b"
   },
   "source": [
    "# LLM Distillation Models\n",
    "\n",
    "<div class=\"align-center\">\n",
    "\n",
    "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
    "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
    "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a>\n",
    "</div>\n",
    "\n",
    "## วัตถุประสงค์การเรียนรู้\n",
    "\n",
    "\n",
    "1. ทดลองใช้โมเดล distilled ระดับ production (DeepSeek-R1-Distill)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntZXV0HxZ-7h"
   },
   "source": [
    "\n",
    "ทดลองใช้ **DeepSeek-R1-Distill-Qwen-1.5B** - โมเดล distilled ระดับ production\n",
    "\n",
    "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ติดตั้ง Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!uv pip install -q transformers accelerate bitsandbytes torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cYhAq7KjZ-7i"
   },
   "outputs": [],
   "source": [
    "deepseek_model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "deepseek_tokenizer = AutoTokenizer.from_pretrained(deepseek_model_name)\n",
    "deepseek_model = AutoModelForCausalLM.from_pretrained(\n",
    "    deepseek_model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(f\"\\n โหลดโมเดล {deepseek_model_name}\")\n",
    "print(f\"  พารามิเตอร์: ~1.5B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ciyC_1s3Z-7i"
   },
   "outputs": [],
   "source": [
    "# สร้าง pipeline\n",
    "deepseek_pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=deepseek_model,\n",
    "    tokenizer=deepseek_tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.7,\n",
    "    do_sample=True,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(\" DeepSeek pipeline พร้อม\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pVfW32KZ-7i"
   },
   "source": [
    "### ทดสอบ DeepSeek กับงาน Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15sug9eAZ-7i"
   },
   "outputs": [],
   "source": [
    "reasoning_tests = [\n",
    "    {\n",
    "        \"name\": \"Math Reasoning\",\n",
    "        \"prompt\": \"\"\"Solve this problem step by step:\n",
    "\n",
    "A store sells notebooks for $3 each and pens for $2 each. If you buy 5 notebooks and 8 pens, how much will you pay in total?\n",
    "\n",
    "Answer:\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Logic Puzzle\",\n",
    "        \"prompt\": \"\"\"Answer this logic puzzle:\n",
    "\n",
    "If all cats are animals, and some animals are pets, can we conclude that all cats are pets?\n",
    "\n",
    "Explain your reasoning:\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Code Generation\",\n",
    "        \"prompt\": \"\"\"Write a Python function to check if a string is a palindrome.\n",
    "\n",
    "Function:\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ทดสอบโมเดล DeepSeek distilled\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for test in reasoning_tests:\n",
    "    print(f\"\\n[{test['name']}]\")\n",
    "    print(\"-\"*60)\n",
    "    print(test['prompt'])\n",
    "    print(\"\\nDeepSeek Response:\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    response = deepseek_pipe(test['prompt'], max_new_tokens=300)[0]['generated_text']\n",
    "    print(response[len(test['prompt']):])\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRvgzEpJZ-7i"
   },
   "source": [
    "## ตรวจสอบประสิทธิภาพการใช้งาน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7eficgkZ-7i"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "test_prompts_perf = [\n",
    "    \"What is the captial city of France?\",\n",
    "    \"Explain Machine Learning in simple words\",\n",
    "    \"Write a haiku about coding.\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"การทดสอบความเร็ว inference\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_time = 0\n",
    "for prompt in test_prompts_perf:\n",
    "    start = time.time()\n",
    "    _ = deepseek_pipe(prompt, max_new_tokens=50)[0]['generated_text']\n",
    "    elapsed = time.time() - start\n",
    "    total_time += elapsed\n",
    "    print(f\"Prompt: {prompt[:40]:40s} | เวลา: {elapsed:.2f}s\")\n",
    "\n",
    "avg_time = total_time / len(test_prompts_perf)\n",
    "print(f\"\\nเวลา inference เฉลี่ย: {avg_time:.2f}s\")\n",
    "print(f\"ขนาดโมเดล: ~1.5B พารามิเตอร์\")\n",
    "print(f\"การใช้หน่วยความจำ: ~3-4 GB VRAM (FP16)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
